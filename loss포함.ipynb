{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPHaplQOpx28VIqIoVJOKWq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonmom/halla_ai/blob/main/loss%ED%8F%AC%ED%95%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWzBqCnbskEF"
      },
      "outputs": [],
      "source": [
        "conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "print(conv1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Pooling example\n",
        "input_example = torch.tensor([[[0, 1.0, 2], [3, 4, 5], [6, 7, 8]]])\n",
        "print(input_example)\n",
        "# max pooling\n",
        "max_pooling_layer = nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "print(max_pooling_layer)\n",
        "print(max_pooling_layer(input_example))\n",
        "# average pooling\n",
        "average_pooling_layer = torch.nn.AvgPool2d(kernel_size=2, stride=1)\n",
        "print(average_pooling_layer)\n",
        "print(average_pooling_layer(input_example))"
      ],
      "metadata": {
        "id": "kKf6wWBgs29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Quiz!!\n",
        "input_example = torch.tensor([[[12, 20, 30, 0.0], [20, 12, 2, 0], [0, 70, 5, 2], [8, 2, 90, 3]]])\n",
        "print(input_example)\n",
        "\n",
        "max_pooling_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "print('\\nmax pooling:\\n', max_pooling_layer(input_example))\n",
        "\n",
        "average_pooling_layer = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "print('\\naverage pooling:\\n', average_pooling_layer(input_example))"
      ],
      "metadata": {
        "id": "3sNd3C0Xs3-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input"
      ],
      "metadata": {
        "id": "g_2u-xH4tXAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.Tensor(1, 1, 32, 32)\n",
        "\n",
        "inputs.shape"
      ],
      "metadata": {
        "id": "dXcWHwBbs95g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 Conv2D\n"
      ],
      "metadata": {
        "id": "iPsvRAxvtD0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "print(conv1)"
      ],
      "metadata": {
        "id": "xJHiLfJwtC44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "두번째 Conv2D"
      ],
      "metadata": {
        "id": "OT5D9zGRtKhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "print(conv2)"
      ],
      "metadata": {
        "id": "SLAtxSfatLWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "MaxPooling"
      ],
      "metadata": {
        "id": "EjXuw6KCtb37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "print(pool)"
      ],
      "metadata": {
        "id": "ndlg2yrItcsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "넣어보기"
      ],
      "metadata": {
        "id": "UuoK9g5ZtfcO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "if9SKnK1tjla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv1(inputs)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "DJy4pPLBtl-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = pool(out)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "LahffX5ztql6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv2(out)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "YCdUHI9Yts8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = pool(out)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "l4K0GAWqtu95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten\n",
        "첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\n",
        "view 함수의 역할\n",
        "view 함수는 텐서의 모양을 변경할 때 사용됩니다. 여기서 out.view(out.size(0), -1)는 다음과 같이 동작합니다:\n",
        "\n",
        "out.size(0)는 첫 번째 차원의 크기, 즉 배치 크기 4를 반환합니다.\n",
        "-1은 PyTorch에게 나머지 차원을 알아서 계산하라는 의미입니다. 이 경우, 나머지 차원은 전체 요소의 수를 첫 번째 차원(배치 차원)의 크기로 나눈 값이 됩니다.\n",
        "\n",
        "torch.Size([4, 1, 28, 28])"
      ],
      "metadata": {
        "id": "SBq7dG5jtyd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.view(out.size(0), -1)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "PK5la1S8tzG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 아래 코드 결과는 [4, 784]는 배치 크기 4와 펼쳐진 나머지 차원(1 * 28 * 28 = 784)을 나타냅니다"
      ],
      "metadata": {
        "id": "IycIA2Qkui7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GUHKDCVqupf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 임의의 텐서 생성 (배치 크기: 4, 채널 수: 1, 높이: 28, 너비: 28)\n",
        "x = torch.randn(4, 1, 28, 28)\n",
        "\n",
        "# nn.Flatten 계층 정의\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "# Flatten 계층을 사용하여 텐서 펼치기\n",
        "out = flatten(x)\n",
        "\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "id": "ITY7GXnJuSAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dense (Fully connected)"
      ],
      "metadata": {
        "id": "OLJ1v_Trv3Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Linear(4096, 10)\n",
        "\n",
        "out = fc(out)\n",
        "\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "ms515q6fv9B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1_CNN 실습\n",
        "pytorch에서 모델 선언하는 3가지 방법"
      ],
      "metadata": {
        "id": "L_ZZn8lwwDZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define CNN model\n",
        "from torch.autograd import Variable\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(CNN1, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        return out  # input image = batch_size x 3 x 16 x 16\n",
        "\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(CNN2, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        return out  # input image = batch_size x 3 x 16 x 16\n",
        "\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(CNN3, self).__init__()\n",
        "        layer = []\n",
        "\n",
        "        layer.append(nn.Conv2d(3, 64, kernel_size=3, padding=1))\n",
        "        layer.append(nn.ReLU())\n",
        "        layer.append(nn.MaxPool2d(2))\n",
        "\n",
        "        self.layer = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        return out  # input image = batch_size x 3 x 16 x 16"
      ],
      "metadata": {
        "id": "lMkw_VgcwMrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R-JpaOt_wNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = Variable(torch.zeros(64, 3, 32, 32))"
      ],
      "metadata": {
        "id": "8MBvID8nwP6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN1()\n",
        "print(cnn)\n",
        "output1 = cnn(sample_image)\n",
        "print(output1.size())"
      ],
      "metadata": {
        "id": "x1GjXAsawSMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN2()\n",
        "print(cnn)\n",
        "output2 = cnn(sample_image)\n",
        "print(output2.size())"
      ],
      "metadata": {
        "id": "iXW1XlX2wUmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN3()\n",
        "print(cnn)\n",
        "output3 = cnn(sample_image)\n",
        "print(output3.size())"
      ],
      "metadata": {
        "id": "20w0-fO3wXcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "네트워크 정의"
      ],
      "metadata": {
        "id": "kTz6I3xGwe9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN_practice1(nn.Module):\n",
        "    def __init__(self, n_classes=10): # input image = batch_size x 3 x 32 x 32\n",
        "        super(CNN_practice1, self).__init__()\n",
        "\n",
        "        # nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 512, 3, 1, 1)  # 512 x 32 x 32\n",
        "        self.conv2 = nn.Conv2d(512, 256, 3, 1, 1)   # 256 x 32 x 32\n",
        "        self.conv3 = nn.Conv2d(256, 256, 3, 2, 1)  # 256 x 16 x 16\n",
        "        self.conv4 = nn.Conv2d(256, 16, 3, 1, 1)  # 16 x 16 x 16 = 4096\n",
        "\n",
        "        self.linear = nn.Linear(16*16*16, n_classes)  # 4096 -> 10\n",
        "\n",
        "    def forward(self, x):\n",
        "        out=self.conv1(x)\n",
        "\n",
        "        out=self.conv2(out)\n",
        "\n",
        "        out=self.conv3(out)\n",
        "\n",
        "        out=self.conv4(out)\n",
        "\n",
        "        out = out.contiguous().view(-1, 256*4*4)\n",
        "\n",
        "        print(out.shape)\n",
        "\n",
        "        out = self.linear(out)\n",
        "\n",
        "        print(out.shape)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "model1=CNN_practice1(n_classes=10).to(device)\n",
        "print(model1)\n",
        "summary(model1, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "vKQGPGZIwdMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_practice2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_practice2, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        # ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model2 = CNN_practice2().to(device)\n",
        "print(model2)\n",
        "summary(model2, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "hSIG0MY9wkbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로스, 옵티마이저 정의"
      ],
      "metadata": {
        "id": "poTyTGFKwyOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model2"
      ],
      "metadata": {
        "id": "Hug-KIEvwx36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qT6L4-5Xw0_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0\n",
        "\n",
        "    for x_train, y_train in data_loader:\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "\n",
        "        y_pred = model(x_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += loss / len(data_loader) # loss / 배치의 갯수\n",
        "\n",
        "    print('[Epoch: {:>4}] loss = {:>.9}'.format(epoch + 1, avg_loss))"
      ],
      "metadata": {
        "id": "T3Mnzmnhw3OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Gradient를 업데이트하지 않는다\n",
        "    x_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    y_test = mnist_test.targets.to(device)\n",
        "\n",
        "    y_pred = model(x_test)\n",
        "    correct_prediction = torch.argmax(y_pred, 1) == y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "id": "HzKE-Bqrw9Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss 99퍼센트로 만들려면?"
      ],
      "metadata": {
        "id": "_y7cO0dexWMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-Layer Network + ReLU + Adam : 96.97%(41090)\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28*28, 50)  # Layer 1\n",
        "        self.fc1 = nn.Linear(50, 30)  # Layer 2\n",
        "        self.fc2 = nn.Linear(30, 10)  # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fc0(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "mnist_net = MNIST_Net().to(device)\n",
        "print('model parameters : %d' % count_parameters(mnist_net))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(mnist_net.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)\n",
        "\n",
        "trainer = Trainer(trainloader=trainDataLoader,\n",
        "                  testloader=testDataLoader,\n",
        "                  net=mnist_net,\n",
        "                  criterion=criterion,\n",
        "                  optimizer=optimizer)\n",
        "\n",
        "trainer.train(epochs=epoch)\n",
        "\n",
        "trainer.test()"
      ],
      "metadata": {
        "id": "nCuW-SSqz5Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVh1LcBjz7NZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}